install.packages("statnet")
install.packages("sna")
install.packages("network")
getwd()
m
m = c(1,3,4,4)
m
dim(m) = c(1,2)
dim(m) = c(2,2)
dim
dim(m)
m
CDItest
mm_test
CDItest
pp_test
is.finite(pp)
is.finite(pp_test)
is.fininte(mm_test)
is.finite(mm_test)
pp_net <- pp[is.finite(pp_test)]
pp_net <- pp_test[is.finite(pp_test)]
pp_net
test_net
net_test <- matrix(c(1:40),4,10)
net_test
pp_net <- net_test[1,2]
pp_net
if.finite(pp_net)
is.finite(pp_net)
CDItest
nettest
networktest
mm
mm_test
pp_test
is.finite(pp_test)
ls()
netfeats
# feature matrix for storage {{{#
netfeats <- matrix(nr=1000, nc=17)#
colnames(netfeats) <- c('age', 'size', 'density', '#isolates', 'average degree', 'max degree', 'assortativity', 'reciprocity','transativity', 'mean geodist', 'diameter', #
                        'mean redundancy', 'betweenness centrality', 'closeness centrality', 'eigen centrality', 'degree centrality', 'word') #}}}#
#
for (i in 1:1000) { # what other measures might we use? #{{{#
  a <- which(tCDI[i,]==1) #
  if (length(a)  > 5) {#
    net <- tnet[a,a] > .2 # this .2 is an arbitrary choice right now#
    inet <- graph_from_adjacency_matrix(net)#
    sz <- ncol(net)#
    den <- gden(net)#
    iso <- length(isolates(net))#
    ad <- mean(sna::degree(net))#
    md <-  max(sna::degree(net))#
    assort <- assortativity_degree(inet)#
    recip <- reciprocity(inet)#
    clu <- gtrans(net)#
    geo <- geodist(net)#
    gdi <- mean(geo$gdist)#
    diam <- max(geo$gdist)#
    red <- mean(geo$counts)#
    between <- centr_betw(inet, normalized = TRUE)$centralization#
    close <- centr_clo(inet, normalized = TRUE)$centralization#
    eigen <- centr_eigen(inet, normalized = TRUE)$centralization#
    degc <- centr_degree(inet,normalized = TRUE)$centralization#
#
    netfeats[i,] <- c(age, sz, den, iso, ad, md, assort, recip, clu, gdi, diam, red, between, close, eigen, degc, word)#
  }#
  age <- kidfeat[i,2]#
  netfeats[i,2] <- length(a)#
  # figure out central words based on betweeness:#
  max_score <- which.max(centr_betw(inet, normalized = TRUE)$res)#
  netfeats[i,17] <- rownames(net)[max_score]  #
} #}}}
require(sna)
require(igraph)
# feature matrix for storage {{{#
netfeats <- matrix(nr=1000, nc=17)#
colnames(netfeats) <- c('age', 'size', 'density', '#isolates', 'average degree', 'max degree', 'assortativity', 'reciprocity','transativity', 'mean geodist', 'diameter', #
                        'mean redundancy', 'betweenness centrality', 'closeness centrality', 'eigen centrality', 'degree centrality', 'word') #}}}#
#
for (i in 1:1000) { # what other measures might we use? #{{{#
  a <- which(tCDI[i,]==1) #
  if (length(a)  > 5) {#
    net <- tnet[a,a] > .2 # this .2 is an arbitrary choice right now#
    inet <- graph_from_adjacency_matrix(net)#
    sz <- ncol(net)#
    den <- gden(net)#
    iso <- length(isolates(net))#
    ad <- mean(sna::degree(net))#
    md <-  max(sna::degree(net))#
    assort <- assortativity_degree(inet)#
    recip <- reciprocity(inet)#
    clu <- gtrans(net)#
    geo <- geodist(net)#
    gdi <- mean(geo$gdist)#
    diam <- max(geo$gdist)#
    red <- mean(geo$counts)#
    between <- centr_betw(inet, normalized = TRUE)$centralization#
    close <- centr_clo(inet, normalized = TRUE)$centralization#
    eigen <- centr_eigen(inet, normalized = TRUE)$centralization#
    degc <- centr_degree(inet,normalized = TRUE)$centralization#
#
    netfeats[i,] <- c(age, sz, den, iso, ad, md, assort, recip, clu, gdi, diam, red, between, close, eigen, degc, word)#
  }#
  age <- kidfeat[i,2]#
  netfeats[i,2] <- length(a)#
  # figure out central words based on betweeness:#
  max_score <- which.max(centr_betw(inet, normalized = TRUE)$res)#
  netfeats[i,17] <- rownames(net)[max_score]  #
} #}}}
netfeats
netfeats <- matrix(nr=1000, nc=17)#
colnames(netfeats) <- c('age', 'size', 'density', '#isolates', 'average degree', 'max degree', 'assortativity', 'reciprocity','transativity', 'mean geodist', 'diameter', #
                        'mean redundancy', 'betweenness centrality', 'closeness centrality', 'eigen centrality', 'degree centrality', 'word') #}}}#
#
for (i in 1:1000) { # what other measures might we use? #{{{#
  a <- which(tCDI[i,]==1) #
  if (length(a)  > 5) {#
    net <- tnet[a,a] > .2 # this .2 is an arbitrary choice right now#
    inet <- graph_from_adjacency_matrix(net)#
    sz <- ncol(net)#
    den <- gden(net)#
    iso <- length(isolates(net))#
    ad <- mean(sna::degree(net))#
    md <-  max(sna::degree(net))#
    assort <- assortativity_degree(inet)#
    recip <- reciprocity(inet)#
    clu <- gtrans(net)#
    geo <- geodist(net)#
    gdi <- mean(geo$gdist)#
    diam <- max(geo$gdist)#
    red <- mean(geo$counts)#
    between <- centr_betw(inet, normalized = TRUE)$centralization#
    close <- centr_clo(inet, normalized = TRUE)$centralization#
    eigen <- centr_eigen(inet, normalized = TRUE)$centralization#
    degc <- centr_degree(inet,normalized = TRUE)$centralization#
#
    netfeats[i,] <- c(age, sz, den, iso, ad, md, assort, recip, clu, gdi, diam, red, between, close, eigen, degc, word)#
  }#
  netfeats[i,1] <- kidfeat[i,2]#
  netfeats[i,2] <- length(a)#
  # figure out central words based on betweeness:#
  max_score <- which.max(centr_betw(inet, normalized = TRUE)$res)#
  netfeats[i,17] <- rownames(net)[max_score]  #
} #}}}
netfeats
head(netfeats)
netfeats[,1]
netfeats
# create correlation table#
corrtable <- matrix(nr = 16 , nc = 16)#
colnames(corrtable) <- colnames(netfeats[,1:16])#
rownames(corrtable) <- colnames(netfeats[,1:16])#
#
for (i in 1:16) {	#
	X <- as.numeric(netfeats[,i])#
	for (j in 1:16) {#
	Y <- as.numeric(netfeats[,j])#
	corrtable[i,j] <- cor(X, Y, use='complete')#
	}#
}
cortable
corrtable
help(write.csv)
write.csv(netfeats, 'Nelson_network_measurments.csv')
list.files
list.files()
getwd()
# feature matrix for storage {{{#
netfeats <- matrix(nr=1000, nc=17)#
colnames(netfeats) <- c('age', 'size', 'density', '#isolates', 'average degree', 'max degree', 'assortativity', 'reciprocity','transativity', 'mean geodist', 'diameter', #
                        'mean redundancy', 'betweenness centrality', 'closeness centrality', 'eigen centrality', 'degree centrality', 'word') #}}}#
#
for (i in 1:1000) { # what other measures might we use? #{{{#
  a <- which(tCDI[i,]==1) #
  if (length(a)  > 0) {#
    net <- tnet[a,a] > .2 # this .2 is an arbitrary choice right now#
    inet <- graph_from_adjacency_matrix(net)#
    sz <- ncol(net)#
    den <- gden(net)#
    iso <- length(isolates(net))#
    ad <- mean(sna::degree(net))#
    md <-  max(sna::degree(net))#
    assort <- assortativity_degree(inet)#
    recip <- reciprocity(inet)#
    clu <- gtrans(net)#
    geo <- geodist(net)#
    gdi <- mean(geo$gdist)#
    diam <- max(geo$gdist)#
    red <- mean(geo$counts)#
    between <- centr_betw(inet, normalized = TRUE)$centralization#
    close <- centr_clo(inet, normalized = TRUE)$centralization#
    eigen <- centr_eigen(inet, normalized = TRUE)$centralization#
    degc <- centr_degree(inet,normalized = TRUE)$centralization#
#
    netfeats[i,] <- c(age, sz, den, iso, ad, md, assort, recip, clu, gdi, diam, red, between, close, eigen, degc, word)#
  }#
  netfeats[i,1] <- kidfeat[i,2]#
  netfeats[i,2] <- length(a)
quit
quit()
ls()
library(tidyverse)      # data manipulation & plotting#
library(stringr)        # text cleaning and regular expressions#
library(tidytext)       # provides additional text mining functions#
library(harrypotter)    # provides the first seven novels of the Harry  Potter series
text_tb <- tibble(chapter = seq_along(philosophers_stone), text = philosophers_stone)
text_tb
text_tb <%<
text_tb <%< unnest_tokens(words,text)
text_tb <%< unnest_token(words,text)
text_tb %>% unnest_token(words,text)
help(unnest_tokens)
install.packages('tidytext')
library(tidytext)
text_tb %>% unnest_token(words,text)
text_tb %>% unnest_tokens(words,text)
lenght(text_tb)
length(text_tb)
length(text_tb[1])
length(text_tb[chapter])
text_tb[1]
text_tb[words]
text_tb[,1]
text_tb[,2]
text_tb[1,2]
text_tb_unnest <- text_tb %>% unnest_tokens(words,text)
text_tb_unnest
length(text_tb_unnest)
text_tb[1]
text_tb[,2]
text_tb[1:2]
text_tb$words
text_tb[words]
text_tb[,2]
text_tb[1,2]
text_tb[2,2]
text_tb[77,865,1]
text_tb(1,2)
text_tb[3,2]
text_tb[17,2]
ls()
p_trans_vs_age
library(parallel)#
library(sna)#
library(igraph)#
library(Rmisc)
require(ascii)#
  require(xtable)#
  require(ggplot2)#
  require(scales)#
  require(reshape2)#
  require(plyr)
p_trans_vs_age
if (!require("pacman")) install.packages("pacman")#
pacman::p_load_gh("trinker/coreNLPsetup", "trinker/stansent"
)
library(RSentiment)
text <- 'love'
calculate_score(text)
calculate_score('death')
calculate_score(jesus)
calculate_score('jesus')
calculate_score('mercy')
calculate_score('chain')
calculate_score('the')
calculate_score('the')[2]
calculate_score('the')[1]
calculate_score('the')[1][2]
j <- calculate_score('the')
j
length(j)
j <- calculate_score('the wolf cried for help')
j
library(coreNLP)
if (!require("pacman")) install.packages("pacman")#
pacman::p_load_gh("trinker/coreNLPsetup", "trinker/stansent")
install.packages("tidytext")
install.packages("pattern.nlp")
install.packages("devtools")#
library(devtools)#
install_github("bnosac/pattern.nlp")
install.packages("RSentiment")
install.packages("plotrix")
install.packages("qdap")
install.packages("tm")
check_setup()
install.packages("â€˜qdapRegex")
install.packages("qdapRegex")
check_setup()
text <- "love"
sentiment_stanford(text)
install.packages('devtools')#
devtools::install_github("statsmaths/coreNLP")
library(rJava)
install.packages('devtools')#
devtools::install_github("statsmaths/coreNLP")
devtools::install_github("statsmaths/coreNLP")#
coreNLP::downloadCoreNLP()
library(tidytext)
library(syuzhet)
library(RSentiment)
library(syuzhet)
library(tm)
stopword
stopwords
stop_words$word
words <- "I looked so much different now. Understanding of morality varies. Suicidal. Adolescence out of place. Just because I survived cancer, doesn't mean I can't have other problems. We can only help you here. Fear of procedures. Every age group has some understanding. Fear of needles. Fear of unknown is scary. Missing school, friends. Recreate routines."
words
input_story_words <- rm_stopwords(words, stopwords = stopwords,#
    unlist = TRUE, separate = FALSE, strip = TRUE, unique = FALSE,#
    char.keep = NULL, names = FALSE, ignore.case = TRUE,#
    apostrophe.remove = FALSE)
library(qdap)
input_story_words <- rm_stopwords(words, stopwords = stopwords,#
    unlist = TRUE, separate = FALSE, strip = TRUE, unique = FALSE,#
    char.keep = NULL, names = FALSE, ignore.case = TRUE,#
    apostrophe.remove = FALSE)
input_story_words <- rm_stopwords(words, stopwords = stop_words$word,#
    unlist = TRUE, separate = FALSE, strip = TRUE, unique = FALSE,#
    char.keep = NULL, names = FALSE, ignore.case = TRUE,#
    apostrophe.remove = FALSE)
input_story_words
library(syuzhet)
get_sentiment_dictionary(dictionary = "syuzhet")
get_sentiment_dictionary(dictionary = "nrc")
head(get_sentiment_dictionary(dictionary = "nrc"))
head(get_sentiment_dictionary(dictionary = "nrc"), 200)
head(get_sentiment_dictionary(dictionary = "nrc"), 500)
get_sentiment_dictionary(dictionary = "nrc")
library(qdap)
s <- "Fuck this shit"
get_tokens(s,pattern="\\W")
library(tidytext)#
library(RSentiment)#
library(pattern.nlp)#
library(syuzhet)#
library(sentimentr)
get_tokens(s,pattern="\\W")
s <- '<where's> [<] your what ?'
s <- "<where's> [<] your what ?"
get_tokens(s,pattern="\\W")
s <- "*MOT:	okay , you wanna sit there xxx ? 19791_20805"
get_tokens(s,pattern="\\W")
getwd()
ls
list.files
getwd()
install.packages(robustbase)
install.packages("robustbase")
install.packages("robustbase", type="binary")
library(caret)
getwd()
setwd('/Users/erickoduniyi/Documents/School/KU/Academics/2018-2019/Research/Hardvard-Forest/Projects/Fruits-Of-Provenance/Construction/Idea-Generation')
getwd()
list.files()
setwd(/)
setwd("/")
getwd()
setwd('/Users/erickoduniyi/Documents/School/KU/Academics/2018-2019/Research/Hardvard-Forest/Projects/Fruits-Of-Provenance/Construction/Idea-Generation')
getwd("/Website-Generation")
getwd("Website-Generation")
setwd("Website-Generation")
list.files()
list.files(0)
list.files()
library(shiny)
getwd()
runApp()
